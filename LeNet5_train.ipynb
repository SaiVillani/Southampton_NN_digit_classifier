{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import models, datasets, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import zipfile\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load experimental data\n",
    "def load_all_experimental_data(test_digits_folder):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    participant_data = {}\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((16, 16)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    for filename in os.listdir(test_digits_folder):\n",
    "        if filename.endswith('.zip') and filename.startswith('experiment_results_participant'):\n",
    "            participant_number = int(filename.split('participant')[1].split('.')[0])\n",
    "            zip_filepath = os.path.join(test_digits_folder, filename)\n",
    "\n",
    "            participant_train_images = []\n",
    "            participant_train_labels = []\n",
    "            participant_test_images = []\n",
    "            participant_test_labels = []\n",
    "\n",
    "            with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "                for img_filename in zip_ref.namelist():\n",
    "                    if img_filename.endswith('.png'):\n",
    "                        with zip_ref.open(img_filename) as file:\n",
    "                            img = Image.open(file).convert('L')\n",
    "                            img_tensor = transform(img)\n",
    "                            \n",
    "                            digit = int(img_filename.split('_')[0])\n",
    "                            \n",
    "                            if 'composite' in img_filename:\n",
    "                                test_images.append(img_tensor)\n",
    "                                test_labels.append(digit)\n",
    "                                participant_test_images.append(img_tensor)\n",
    "                                participant_test_labels.append(digit)\n",
    "                            else:\n",
    "                                train_images.append(img_tensor)\n",
    "                                train_labels.append(digit)\n",
    "                                participant_train_images.append(img_tensor)\n",
    "                                participant_train_labels.append(digit)\n",
    "\n",
    "            participant_data[participant_number] = {\n",
    "                'train': (torch.stack(participant_train_images), torch.tensor(participant_train_labels)),\n",
    "                'test': (torch.stack(participant_test_images), torch.tensor(participant_test_labels))\n",
    "            }\n",
    "\n",
    "    return (torch.stack(train_images), torch.tensor(train_labels), \n",
    "            torch.stack(test_images), torch.tensor(test_labels),\n",
    "            participant_data)\n",
    "\n",
    "# Load experimental data\n",
    "exp_train_images, exp_train_labels, exp_test_images, exp_test_labels, participant_data = load_all_experimental_data('test_digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the test data into validation and test sets\n",
    "val_images, final_test_images, val_labels, final_test_labels = train_test_split(\n",
    "    exp_test_images, exp_test_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Assuming exp_train_images and exp_train_labels are already loaded\n",
    "train_dataset = TensorDataset(exp_train_images, exp_train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create DataLoader for validation set\n",
    "val_dataset = torch.utils.data.TensorDataset(val_images, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create DataLoader for final test set\n",
    "test_dataset = torch.utils.data.TensorDataset(final_test_images, final_test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define LeNet5 architecture modified for 16x16 images\n",
    "class LeNet5_16x16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5_16x16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)  # Adjusted for 16x16 input size\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Load LeNet5 model for 16x16 images\n",
    "def load_lenet5_model_16x16():\n",
    "    model = LeNet5_16x16(num_classes=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 2408.0627\n",
      "Validation Accuracy: 68.42%\n",
      "Epoch [2/15], Loss: 2377.3934\n",
      "Validation Accuracy: 73.68%\n",
      "Epoch [3/15], Loss: 2365.0198\n",
      "Validation Accuracy: 75.79%\n",
      "Epoch [4/15], Loss: 2358.5327\n",
      "Validation Accuracy: 85.26%\n",
      "Epoch [5/15], Loss: 2354.6844\n",
      "Validation Accuracy: 90.53%\n",
      "Epoch [6/15], Loss: 2351.0160\n",
      "Validation Accuracy: 90.53%\n",
      "Epoch [7/15], Loss: 2346.9722\n",
      "Validation Accuracy: 74.74%\n",
      "Epoch [8/15], Loss: 2344.3531\n",
      "Validation Accuracy: 86.32%\n",
      "Epoch [9/15], Loss: 2342.2535\n",
      "Validation Accuracy: 88.42%\n",
      "Epoch [10/15], Loss: 2341.1659\n",
      "Validation Accuracy: 96.84%\n",
      "Epoch [11/15], Loss: 2339.2536\n",
      "Validation Accuracy: 94.74%\n",
      "Epoch [12/15], Loss: 2337.6042\n",
      "Validation Accuracy: 95.79%\n",
      "Epoch [13/15], Loss: 2336.2158\n",
      "Validation Accuracy: 89.47%\n",
      "Epoch [14/15], Loss: 2334.8472\n",
      "Validation Accuracy: 88.42%\n",
      "Epoch [15/15], Loss: 2334.1785\n",
      "Validation Accuracy: 93.68%\n",
      "Model saved to lenet5_trained_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning function for LeNet5 on your dataset\n",
    "def fine_tune_lenet(model, train_loader, val_loader=None, num_epochs=15, save_path=\"lenet5_model.pth\"):\n",
    "    criterion = nn.CrossEntropyLoss()  # Loss function for classification tasks\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            \n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            \n",
    "            loss.backward()  # Backward pass (compute gradients)\n",
    "            optimizer.step()  # Update weights\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}')\n",
    "        \n",
    "        # Validation loop (if validation set is provided)\n",
    "        if val_loader:\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            model.eval()  # Set model to evaluation mode during validation\n",
    "            \n",
    "            with torch.no_grad():  # Disable gradient computation during validation\n",
    "                for val_images_batch, val_labels_batch in val_loader:\n",
    "                    outputs_val = model(val_images_batch)\n",
    "                    _, predicted_val = torch.max(outputs_val.data, 1)   # Get predicted class\n",
    "                    \n",
    "                    total_val += val_labels_batch.size(0)\n",
    "                    correct_val += (predicted_val == val_labels_batch).sum().item()\n",
    "            \n",
    "            print(f'Validation Accuracy: {100 * correct_val / total_val:.2f}%')\n",
    "            \n",
    "            model.train()  # Switch back to training mode after validation\n",
    "\n",
    "    # Save the trained model after training is complete\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# Example usage:\n",
    "lenet_model_16x16 = load_lenet5_model_16x16()\n",
    "fine_tune_lenet(lenet_model_16x16, train_loader=train_loader, val_loader=val_loader, save_path=\"lenet5_trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on final test images: 91.58%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_lenet(model, test_loader):\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for images_batch_test, labels_batch_test in test_loader:\n",
    "            outputs_test = model(images_batch_test)\n",
    "            _, predicted_test_classifications = torch.max(outputs_test.data, 1)   # Get predicted class\n",
    "            \n",
    "            total_test += labels_batch_test.size(0)\n",
    "            correct_test += (predicted_test_classifications == labels_batch_test).sum().item()\n",
    "    \n",
    "    print(f'Accuracy of the network on final test images: {100 * correct_test / total_test:.2f}%')\n",
    "\n",
    "# Evaluate on final test set after training is complete\n",
    "evaluate_lenet(lenet_model_16x16, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
