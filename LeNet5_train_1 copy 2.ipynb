{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, ConcatDataset\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import os\n",
    "import zipfile\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental data\n",
    "def load_all_experimental_data(test_digits_folder):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    participant_data = {}\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((16, 16)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    for filename in os.listdir(test_digits_folder):\n",
    "        if filename.endswith('.zip') and filename.startswith('experiment_results_participant'):\n",
    "            participant_number = int(filename.split('participant')[1].split('.')[0])\n",
    "            zip_filepath = os.path.join(test_digits_folder, filename)\n",
    "\n",
    "            participant_train_images = []\n",
    "            participant_train_labels = []\n",
    "            participant_test_images = []\n",
    "            participant_test_labels = []\n",
    "\n",
    "            with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "                for img_filename in zip_ref.namelist():\n",
    "                    if img_filename.endswith('.png'):\n",
    "                        with zip_ref.open(img_filename) as file:\n",
    "                            img = Image.open(file).convert('L')\n",
    "                            img_tensor = transform(img)\n",
    "                            \n",
    "                            digit = int(img_filename.split('_')[0])\n",
    "                            \n",
    "                            if 'composite' in img_filename:\n",
    "                                test_images.append(img_tensor)\n",
    "                                test_labels.append(digit)\n",
    "                                participant_test_images.append(img_tensor)\n",
    "                                participant_test_labels.append(digit)\n",
    "                            else:\n",
    "                                train_images.append(img_tensor)\n",
    "                                train_labels.append(digit)\n",
    "                                participant_train_images.append(img_tensor)\n",
    "                                participant_train_labels.append(digit)\n",
    "\n",
    "            participant_data[participant_number] = {\n",
    "                'train': (torch.stack(participant_train_images), torch.tensor(participant_train_labels)),\n",
    "                'test': (torch.stack(participant_test_images), torch.tensor(participant_test_labels))\n",
    "            }\n",
    "\n",
    "    return (torch.stack(train_images), torch.tensor(train_labels), \n",
    "            torch.stack(test_images), torch.tensor(test_labels),\n",
    "            participant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(self.dataset, TensorDataset):\n",
    "            x, y = self.dataset[index]\n",
    "        else:\n",
    "            x, y = self.dataset[index]\n",
    "        \n",
    "        # Ensure x is a tensor\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x)\n",
    "        \n",
    "        # Ensure y is a tensor\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.tensor(y)\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class LeNet5_16x16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5_16x16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience):\n",
    "    model = model.to(device)\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}')\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                outputs_val = model(val_images)\n",
    "                _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (predicted_val == val_labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "def k_fold_cross_validation(dataset, num_folds=5, num_epochs=50, patience=5):\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(range(len(dataset)))):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_index)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_index)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = LeNet5_16x16(num_classes=10).to(device)\n",
    "        \n",
    "        # Calculate class weights for weighted cross-entropy\n",
    "        labels = torch.tensor([dataset[i][1] for i in train_index])\n",
    "        class_counts = torch.bincount(labels)\n",
    "        class_weights = 1. / class_counts.float()\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                outputs_val = model(val_images)\n",
    "                _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (predicted_val == val_labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        fold_results.append(val_accuracy)\n",
    "        print(f'Fold {fold + 1} Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/25\n",
      "Fold 1/5\n",
      "Epoch [1/50], Loss: 7577.5870\n",
      "Validation Accuracy: 58.17%\n",
      "Epoch [2/50], Loss: 4494.5134\n",
      "Validation Accuracy: 63.00%\n",
      "Epoch [3/50], Loss: 4196.8570\n",
      "Validation Accuracy: 65.15%\n",
      "Epoch [4/50], Loss: 4051.8584\n",
      "Validation Accuracy: 66.62%\n",
      "Epoch [5/50], Loss: 3962.2350\n",
      "Validation Accuracy: 67.14%\n",
      "Epoch [6/50], Loss: 3852.5062\n",
      "Validation Accuracy: 67.49%\n",
      "Epoch [7/50], Loss: 3766.4145\n",
      "Validation Accuracy: 66.74%\n",
      "Epoch [8/50], Loss: 3709.6358\n",
      "Validation Accuracy: 67.93%\n",
      "Epoch [9/50], Loss: 3676.0608\n",
      "Validation Accuracy: 68.20%\n",
      "Epoch [10/50], Loss: 3609.9273\n",
      "Validation Accuracy: 69.15%\n",
      "Epoch [11/50], Loss: 3570.3856\n",
      "Validation Accuracy: 69.08%\n",
      "Epoch [12/50], Loss: 3529.6642\n",
      "Validation Accuracy: 69.39%\n",
      "Epoch [13/50], Loss: 3510.8801\n",
      "Validation Accuracy: 69.84%\n",
      "Epoch [14/50], Loss: 3470.1554\n",
      "Validation Accuracy: 70.36%\n",
      "Epoch [15/50], Loss: 3439.8056\n",
      "Validation Accuracy: 70.32%\n",
      "Epoch [16/50], Loss: 3436.1097\n",
      "Validation Accuracy: 70.40%\n",
      "Epoch [17/50], Loss: 3392.9126\n",
      "Validation Accuracy: 71.01%\n",
      "Epoch [18/50], Loss: 3371.0490\n",
      "Validation Accuracy: 70.80%\n",
      "Epoch [19/50], Loss: 3354.3295\n",
      "Validation Accuracy: 70.76%\n",
      "Epoch [20/50], Loss: 3347.0015\n",
      "Validation Accuracy: 71.16%\n",
      "Epoch [21/50], Loss: 3323.7680\n",
      "Validation Accuracy: 71.58%\n",
      "Epoch [22/50], Loss: 3292.9304\n",
      "Validation Accuracy: 71.38%\n",
      "Epoch [23/50], Loss: 3302.2858\n",
      "Validation Accuracy: 70.93%\n",
      "Epoch [24/50], Loss: 3270.2956\n",
      "Validation Accuracy: 71.17%\n",
      "Epoch [25/50], Loss: 3265.4201\n",
      "Validation Accuracy: 69.97%\n",
      "Epoch [26/50], Loss: 3263.9110\n",
      "Validation Accuracy: 71.78%\n",
      "Epoch [27/50], Loss: 3247.5346\n",
      "Validation Accuracy: 71.42%\n",
      "Epoch [28/50], Loss: 3223.8033\n",
      "Validation Accuracy: 71.50%\n",
      "Epoch [29/50], Loss: 3214.5004\n",
      "Validation Accuracy: 71.72%\n",
      "Epoch [30/50], Loss: 3208.2472\n",
      "Validation Accuracy: 71.79%\n",
      "Epoch [31/50], Loss: 3201.9020\n",
      "Validation Accuracy: 71.79%\n",
      "Epoch [32/50], Loss: 3194.9731\n",
      "Validation Accuracy: 71.69%\n",
      "Epoch [33/50], Loss: 3178.3526\n",
      "Validation Accuracy: 72.09%\n",
      "Epoch [34/50], Loss: 3171.5224\n",
      "Validation Accuracy: 71.95%\n",
      "Epoch [35/50], Loss: 3161.3880\n",
      "Validation Accuracy: 72.07%\n",
      "Epoch [36/50], Loss: 3154.4020\n",
      "Validation Accuracy: 72.08%\n",
      "Epoch [37/50], Loss: 3153.9837\n",
      "Validation Accuracy: 72.52%\n",
      "Epoch [38/50], Loss: 3136.8421\n",
      "Validation Accuracy: 72.25%\n",
      "Epoch [39/50], Loss: 3136.6287\n",
      "Validation Accuracy: 72.17%\n",
      "Epoch [40/50], Loss: 3122.5807\n",
      "Validation Accuracy: 72.29%\n",
      "Epoch [41/50], Loss: 3107.9096\n",
      "Validation Accuracy: 72.19%\n",
      "Epoch [42/50], Loss: 3106.5128\n",
      "Validation Accuracy: 71.92%\n",
      "Early stopping triggered after 42 epochs\n",
      "Fold 1 Validation Accuracy: 72.06%\n",
      "Fold 2/5\n",
      "Epoch [1/50], Loss: 7380.7812\n",
      "Validation Accuracy: 57.61%\n",
      "Epoch [2/50], Loss: 4372.6479\n",
      "Validation Accuracy: 64.59%\n",
      "Epoch [3/50], Loss: 3949.2360\n",
      "Validation Accuracy: 67.72%\n",
      "Epoch [4/50], Loss: 3790.1141\n",
      "Validation Accuracy: 68.02%\n",
      "Epoch [5/50], Loss: 3649.0330\n",
      "Validation Accuracy: 69.35%\n",
      "Epoch [6/50], Loss: 3571.1538\n",
      "Validation Accuracy: 69.73%\n",
      "Epoch [7/50], Loss: 3506.5585\n",
      "Validation Accuracy: 69.85%\n",
      "Epoch [8/50], Loss: 3454.3364\n",
      "Validation Accuracy: 70.49%\n",
      "Epoch [9/50], Loss: 3420.2526\n",
      "Validation Accuracy: 70.11%\n",
      "Epoch [10/50], Loss: 3392.2944\n",
      "Validation Accuracy: 70.26%\n",
      "Epoch [11/50], Loss: 3350.7778\n",
      "Validation Accuracy: 70.77%\n",
      "Epoch [12/50], Loss: 3338.4307\n",
      "Validation Accuracy: 70.58%\n",
      "Epoch [13/50], Loss: 3304.7856\n",
      "Validation Accuracy: 70.88%\n",
      "Epoch [14/50], Loss: 3293.5494\n",
      "Validation Accuracy: 71.05%\n",
      "Epoch [15/50], Loss: 3271.3140\n",
      "Validation Accuracy: 70.99%\n",
      "Epoch [16/50], Loss: 3248.9697\n",
      "Validation Accuracy: 71.45%\n",
      "Epoch [17/50], Loss: 3229.9715\n",
      "Validation Accuracy: 71.36%\n",
      "Epoch [18/50], Loss: 3226.6750\n",
      "Validation Accuracy: 71.32%\n",
      "Epoch [19/50], Loss: 3206.9093\n",
      "Validation Accuracy: 71.73%\n",
      "Epoch [20/50], Loss: 3203.4993\n",
      "Validation Accuracy: 71.68%\n",
      "Epoch [21/50], Loss: 3194.2630\n",
      "Validation Accuracy: 71.76%\n",
      "Epoch [22/50], Loss: 3170.0629\n",
      "Validation Accuracy: 71.81%\n",
      "Epoch [23/50], Loss: 3171.3744\n",
      "Validation Accuracy: 71.13%\n",
      "Epoch [24/50], Loss: 3166.8449\n",
      "Validation Accuracy: 71.52%\n",
      "Epoch [25/50], Loss: 3148.8193\n",
      "Validation Accuracy: 72.18%\n",
      "Epoch [26/50], Loss: 3138.3436\n",
      "Validation Accuracy: 71.81%\n",
      "Epoch [27/50], Loss: 3136.6546\n",
      "Validation Accuracy: 71.26%\n",
      "Epoch [28/50], Loss: 3141.9337\n",
      "Validation Accuracy: 71.79%\n",
      "Epoch [29/50], Loss: 3116.2283\n",
      "Validation Accuracy: 71.81%\n",
      "Epoch [30/50], Loss: 3120.3202\n",
      "Validation Accuracy: 72.20%\n",
      "Epoch [31/50], Loss: 3102.9921\n",
      "Validation Accuracy: 72.49%\n",
      "Epoch [32/50], Loss: 3101.6262\n",
      "Validation Accuracy: 72.32%\n",
      "Epoch [33/50], Loss: 3083.9387\n",
      "Validation Accuracy: 72.23%\n",
      "Epoch [34/50], Loss: 3094.8788\n",
      "Validation Accuracy: 71.84%\n",
      "Epoch [35/50], Loss: 3073.8509\n",
      "Validation Accuracy: 72.54%\n",
      "Epoch [36/50], Loss: 3075.7497\n",
      "Validation Accuracy: 72.14%\n",
      "Epoch [37/50], Loss: 3070.0262\n",
      "Validation Accuracy: 72.09%\n",
      "Epoch [38/50], Loss: 3078.9022\n",
      "Validation Accuracy: 72.03%\n",
      "Epoch [39/50], Loss: 3057.8102\n",
      "Validation Accuracy: 72.06%\n",
      "Epoch [40/50], Loss: 3064.5913\n",
      "Validation Accuracy: 72.18%\n",
      "Early stopping triggered after 40 epochs\n",
      "Fold 2 Validation Accuracy: 71.81%\n",
      "Fold 3/5\n",
      "Epoch [1/50], Loss: 7619.4560\n",
      "Validation Accuracy: 58.40%\n",
      "Epoch [2/50], Loss: 4530.9319\n",
      "Validation Accuracy: 64.72%\n",
      "Epoch [3/50], Loss: 4194.1395\n",
      "Validation Accuracy: 65.98%\n",
      "Epoch [4/50], Loss: 3982.8415\n",
      "Validation Accuracy: 67.56%\n",
      "Epoch [5/50], Loss: 3855.5931\n",
      "Validation Accuracy: 68.81%\n",
      "Epoch [6/50], Loss: 3770.1060\n",
      "Validation Accuracy: 68.70%\n",
      "Epoch [7/50], Loss: 3699.2430\n",
      "Validation Accuracy: 69.86%\n",
      "Epoch [8/50], Loss: 3639.8092\n",
      "Validation Accuracy: 69.13%\n",
      "Epoch [9/50], Loss: 3609.3127\n",
      "Validation Accuracy: 70.06%\n",
      "Epoch [10/50], Loss: 3563.6627\n",
      "Validation Accuracy: 70.49%\n",
      "Epoch [11/50], Loss: 3543.3014\n",
      "Validation Accuracy: 70.27%\n",
      "Epoch [12/50], Loss: 3518.9851\n",
      "Validation Accuracy: 70.10%\n",
      "Epoch [13/50], Loss: 3481.8980\n",
      "Validation Accuracy: 70.69%\n",
      "Epoch [14/50], Loss: 3449.0225\n",
      "Validation Accuracy: 70.50%\n",
      "Epoch [15/50], Loss: 3428.6362\n",
      "Validation Accuracy: 71.43%\n",
      "Epoch [16/50], Loss: 3414.9394\n",
      "Validation Accuracy: 70.62%\n",
      "Epoch [17/50], Loss: 3391.4384\n",
      "Validation Accuracy: 71.28%\n",
      "Epoch [18/50], Loss: 3369.2242\n",
      "Validation Accuracy: 70.66%\n",
      "Epoch [19/50], Loss: 3361.2006\n",
      "Validation Accuracy: 71.54%\n",
      "Epoch [20/50], Loss: 3349.4759\n",
      "Validation Accuracy: 70.77%\n",
      "Epoch [21/50], Loss: 3327.2173\n",
      "Validation Accuracy: 71.65%\n",
      "Epoch [22/50], Loss: 3333.1459\n",
      "Validation Accuracy: 71.27%\n",
      "Epoch [23/50], Loss: 3309.5849\n",
      "Validation Accuracy: 71.33%\n",
      "Epoch [24/50], Loss: 3298.9051\n",
      "Validation Accuracy: 71.56%\n",
      "Epoch [25/50], Loss: 3289.7619\n",
      "Validation Accuracy: 72.10%\n",
      "Epoch [26/50], Loss: 3283.4029\n",
      "Validation Accuracy: 71.35%\n",
      "Epoch [27/50], Loss: 3274.7425\n",
      "Validation Accuracy: 71.46%\n",
      "Epoch [28/50], Loss: 3266.3792\n",
      "Validation Accuracy: 71.56%\n",
      "Epoch [29/50], Loss: 3262.0101\n",
      "Validation Accuracy: 71.66%\n",
      "Epoch [30/50], Loss: 3254.9362\n",
      "Validation Accuracy: 72.02%\n",
      "Early stopping triggered after 30 epochs\n",
      "Fold 3 Validation Accuracy: 71.92%\n",
      "Fold 4/5\n",
      "Epoch [1/50], Loss: 6618.6925\n",
      "Validation Accuracy: 55.74%\n",
      "Epoch [2/50], Loss: 4767.6779\n",
      "Validation Accuracy: 61.66%\n",
      "Epoch [3/50], Loss: 4151.5688\n",
      "Validation Accuracy: 66.29%\n",
      "Epoch [4/50], Loss: 3835.7624\n",
      "Validation Accuracy: 68.25%\n",
      "Epoch [5/50], Loss: 3683.1309\n",
      "Validation Accuracy: 67.55%\n",
      "Epoch [6/50], Loss: 3581.2048\n",
      "Validation Accuracy: 68.68%\n",
      "Epoch [7/50], Loss: 3506.3845\n",
      "Validation Accuracy: 69.43%\n",
      "Epoch [8/50], Loss: 3442.8362\n",
      "Validation Accuracy: 68.68%\n",
      "Epoch [9/50], Loss: 3407.5829\n",
      "Validation Accuracy: 69.15%\n",
      "Epoch [10/50], Loss: 3370.9161\n",
      "Validation Accuracy: 69.10%\n",
      "Epoch [11/50], Loss: 3338.8240\n",
      "Validation Accuracy: 69.91%\n",
      "Epoch [12/50], Loss: 3303.2040\n",
      "Validation Accuracy: 70.06%\n",
      "Epoch [13/50], Loss: 3286.5187\n",
      "Validation Accuracy: 70.27%\n",
      "Epoch [14/50], Loss: 3269.2801\n",
      "Validation Accuracy: 70.68%\n",
      "Epoch [15/50], Loss: 3254.7583\n",
      "Validation Accuracy: 70.36%\n",
      "Epoch [16/50], Loss: 3242.6135\n",
      "Validation Accuracy: 70.65%\n",
      "Epoch [17/50], Loss: 3225.9394\n",
      "Validation Accuracy: 70.64%\n",
      "Epoch [18/50], Loss: 3209.2987\n",
      "Validation Accuracy: 71.08%\n",
      "Epoch [19/50], Loss: 3193.2896\n",
      "Validation Accuracy: 69.16%\n",
      "Epoch [20/50], Loss: 3194.2198\n",
      "Validation Accuracy: 71.23%\n",
      "Epoch [21/50], Loss: 3164.8723\n",
      "Validation Accuracy: 70.78%\n",
      "Epoch [22/50], Loss: 3157.6704\n",
      "Validation Accuracy: 70.82%\n",
      "Epoch [23/50], Loss: 3152.0408\n",
      "Validation Accuracy: 70.80%\n",
      "Epoch [24/50], Loss: 3151.1113\n",
      "Validation Accuracy: 71.36%\n",
      "Epoch [25/50], Loss: 3144.6470\n",
      "Validation Accuracy: 70.95%\n",
      "Epoch [26/50], Loss: 3137.2792\n",
      "Validation Accuracy: 71.84%\n",
      "Epoch [27/50], Loss: 3136.0493\n",
      "Validation Accuracy: 70.77%\n",
      "Epoch [28/50], Loss: 3136.8433\n",
      "Validation Accuracy: 70.74%\n",
      "Epoch [29/50], Loss: 3109.5437\n",
      "Validation Accuracy: 71.31%\n",
      "Epoch [30/50], Loss: 3111.8327\n",
      "Validation Accuracy: 71.57%\n",
      "Epoch [31/50], Loss: 3097.4006\n",
      "Validation Accuracy: 71.55%\n",
      "Early stopping triggered after 31 epochs\n",
      "Fold 4 Validation Accuracy: 71.71%\n",
      "Fold 5/5\n",
      "Epoch [1/50], Loss: 6676.6557\n",
      "Validation Accuracy: 52.84%\n",
      "Epoch [2/50], Loss: 5018.8449\n",
      "Validation Accuracy: 58.91%\n",
      "Epoch [3/50], Loss: 4306.1292\n",
      "Validation Accuracy: 64.03%\n",
      "Epoch [4/50], Loss: 3938.4101\n",
      "Validation Accuracy: 66.67%\n",
      "Epoch [5/50], Loss: 3751.3436\n",
      "Validation Accuracy: 67.46%\n",
      "Epoch [6/50], Loss: 3644.8878\n",
      "Validation Accuracy: 68.66%\n",
      "Epoch [7/50], Loss: 3570.0040\n",
      "Validation Accuracy: 67.85%\n",
      "Epoch [8/50], Loss: 3531.5224\n",
      "Validation Accuracy: 68.93%\n",
      "Epoch [9/50], Loss: 3469.6534\n",
      "Validation Accuracy: 67.26%\n",
      "Epoch [10/50], Loss: 3449.0660\n",
      "Validation Accuracy: 69.43%\n",
      "Epoch [11/50], Loss: 3413.1224\n",
      "Validation Accuracy: 70.14%\n",
      "Epoch [12/50], Loss: 3384.8865\n",
      "Validation Accuracy: 68.67%\n",
      "Epoch [13/50], Loss: 3354.9805\n",
      "Validation Accuracy: 70.19%\n",
      "Epoch [14/50], Loss: 3331.3601\n",
      "Validation Accuracy: 69.50%\n",
      "Epoch [15/50], Loss: 3314.2636\n",
      "Validation Accuracy: 70.16%\n",
      "Epoch [16/50], Loss: 3291.4925\n",
      "Validation Accuracy: 70.03%\n",
      "Epoch [17/50], Loss: 3276.9124\n",
      "Validation Accuracy: 70.53%\n",
      "Epoch [18/50], Loss: 3257.4687\n",
      "Validation Accuracy: 70.32%\n",
      "Epoch [19/50], Loss: 3240.3863\n",
      "Validation Accuracy: 70.70%\n",
      "Epoch [20/50], Loss: 3220.3551\n",
      "Validation Accuracy: 71.12%\n",
      "Epoch [21/50], Loss: 3208.1145\n",
      "Validation Accuracy: 70.66%\n",
      "Epoch [22/50], Loss: 3191.6257\n",
      "Validation Accuracy: 70.46%\n",
      "Epoch [23/50], Loss: 3186.1332\n",
      "Validation Accuracy: 70.89%\n",
      "Epoch [24/50], Loss: 3170.7291\n",
      "Validation Accuracy: 71.12%\n",
      "Epoch [25/50], Loss: 3154.3025\n",
      "Validation Accuracy: 71.05%\n",
      "Epoch [26/50], Loss: 3138.1434\n",
      "Validation Accuracy: 70.88%\n",
      "Epoch [27/50], Loss: 3128.7769\n",
      "Validation Accuracy: 70.25%\n",
      "Epoch [28/50], Loss: 3134.0072\n",
      "Validation Accuracy: 70.77%\n",
      "Epoch [29/50], Loss: 3126.0744\n",
      "Validation Accuracy: 71.99%\n",
      "Epoch [30/50], Loss: 3108.0496\n",
      "Validation Accuracy: 71.39%\n",
      "Epoch [31/50], Loss: 3091.6706\n",
      "Validation Accuracy: 71.60%\n",
      "Epoch [32/50], Loss: 3091.4157\n",
      "Validation Accuracy: 71.19%\n",
      "Epoch [33/50], Loss: 3087.8356\n",
      "Validation Accuracy: 71.61%\n",
      "Epoch [34/50], Loss: 3074.0632\n",
      "Validation Accuracy: 71.59%\n",
      "Early stopping triggered after 34 epochs\n",
      "Fold 5 Validation Accuracy: 71.51%\n",
      "Model 1 - Average Validation Accuracy across folds: 71.80%\n",
      "Epoch [1/50], Loss: 8106.2510\n",
      "Validation Accuracy: 65.59%\n",
      "Epoch [2/50], Loss: 6050.0367\n",
      "Validation Accuracy: 77.84%\n",
      "Epoch [3/50], Loss: 5307.4537\n",
      "Validation Accuracy: 81.55%\n",
      "Epoch [4/50], Loss: 5014.8816\n",
      "Validation Accuracy: 84.09%\n",
      "Epoch [5/50], Loss: 4836.2121\n",
      "Validation Accuracy: 84.42%\n",
      "Epoch [6/50], Loss: 4708.5155\n",
      "Validation Accuracy: 84.48%\n",
      "Epoch [7/50], Loss: 4578.0240\n",
      "Validation Accuracy: 85.92%\n",
      "Epoch [8/50], Loss: 4497.5607\n",
      "Validation Accuracy: 85.64%\n",
      "Epoch [9/50], Loss: 4421.4643\n",
      "Validation Accuracy: 86.12%\n",
      "Epoch [10/50], Loss: 4339.3231\n",
      "Validation Accuracy: 87.44%\n",
      "Epoch [11/50], Loss: 4285.3261\n",
      "Validation Accuracy: 87.30%\n",
      "Epoch [12/50], Loss: 4238.0061\n",
      "Validation Accuracy: 87.93%\n",
      "Epoch [13/50], Loss: 4185.9710\n",
      "Validation Accuracy: 87.96%\n",
      "Epoch [14/50], Loss: 4148.7771\n",
      "Validation Accuracy: 87.70%\n",
      "Epoch [15/50], Loss: 4105.8906\n",
      "Validation Accuracy: 88.25%\n",
      "Epoch [16/50], Loss: 4087.7093\n",
      "Validation Accuracy: 88.57%\n",
      "Epoch [17/50], Loss: 4057.0120\n",
      "Validation Accuracy: 88.61%\n",
      "Epoch [18/50], Loss: 4052.2502\n",
      "Validation Accuracy: 88.98%\n",
      "Epoch [19/50], Loss: 4021.9162\n",
      "Validation Accuracy: 89.15%\n",
      "Epoch [20/50], Loss: 4000.0637\n",
      "Validation Accuracy: 88.97%\n",
      "Epoch [21/50], Loss: 3985.6000\n",
      "Validation Accuracy: 88.14%\n",
      "Epoch [22/50], Loss: 3982.7291\n",
      "Validation Accuracy: 89.08%\n",
      "Epoch [23/50], Loss: 3962.5948\n",
      "Validation Accuracy: 89.11%\n",
      "Epoch [24/50], Loss: 3956.6924\n",
      "Validation Accuracy: 89.58%\n",
      "Epoch [25/50], Loss: 3956.4492\n",
      "Validation Accuracy: 89.31%\n",
      "Epoch [26/50], Loss: 3939.5874\n",
      "Validation Accuracy: 89.28%\n",
      "Epoch [27/50], Loss: 3936.1866\n",
      "Validation Accuracy: 89.00%\n",
      "Epoch [28/50], Loss: 3930.1168\n",
      "Validation Accuracy: 89.25%\n",
      "Epoch [29/50], Loss: 3929.0259\n",
      "Validation Accuracy: 89.33%\n",
      "Early stopping triggered after 29 epochs\n",
      "Model 1 saved as lenet5_trained_model_ensemble_1.pth\n",
      "Training model 2/25\n",
      "Fold 1/5\n",
      "Epoch [1/50], Loss: 7310.1931\n",
      "Validation Accuracy: 60.28%\n",
      "Epoch [2/50], Loss: 4383.9933\n",
      "Validation Accuracy: 66.21%\n",
      "Epoch [3/50], Loss: 4030.7650\n",
      "Validation Accuracy: 67.37%\n",
      "Epoch [4/50], Loss: 3886.0829\n",
      "Validation Accuracy: 66.92%\n",
      "Epoch [5/50], Loss: 3792.1598\n",
      "Validation Accuracy: 68.69%\n",
      "Epoch [6/50], Loss: 3713.0782\n",
      "Validation Accuracy: 69.05%\n",
      "Epoch [7/50], Loss: 3649.8508\n",
      "Validation Accuracy: 70.25%\n",
      "Epoch [8/50], Loss: 3607.9327\n",
      "Validation Accuracy: 69.95%\n",
      "Epoch [9/50], Loss: 3576.7161\n",
      "Validation Accuracy: 71.09%\n",
      "Epoch [10/50], Loss: 3542.5214\n",
      "Validation Accuracy: 70.45%\n",
      "Epoch [11/50], Loss: 3504.4199\n",
      "Validation Accuracy: 70.71%\n",
      "Epoch [12/50], Loss: 3488.0455\n",
      "Validation Accuracy: 71.12%\n",
      "Epoch [13/50], Loss: 3477.4829\n",
      "Validation Accuracy: 71.14%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Additional data augmentation techniques\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "def load_augmented_mnist():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((16, 16)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "            AddGaussianNoise(0., 0.05),\n",
    "        ], p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n",
    "        ], p=0.3),\n",
    "    ])\n",
    "    \n",
    "    invert_transform = transforms.Compose([\n",
    "        transform,\n",
    "        transforms.Lambda(lambda x: 1 - x),\n",
    "    ])\n",
    "    \n",
    "    mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    inverted_mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=invert_transform)\n",
    "    inverted_mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=invert_transform)\n",
    "    \n",
    "    combined_train = ConcatDataset([mnist_train, inverted_mnist_train])\n",
    "    combined_test = ConcatDataset([mnist_test, inverted_mnist_test])\n",
    "    \n",
    "    return combined_train, combined_test\n",
    "\n",
    "def train_ensemble(num_models=25, num_folds=5, num_epochs=50, patience=5):\n",
    "    ensemble = []\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        print(f\"Training model {i+1}/{num_models}\")\n",
    "        \n",
    "        # Load experimental data\n",
    "        exp_train_images, exp_train_labels, exp_test_images, exp_test_labels, participant_data = load_all_experimental_data('test_digits')\n",
    "        exp_dataset = TensorDataset(exp_train_images, exp_train_labels)\n",
    "\n",
    "        # Load augmented MNIST data\n",
    "        mnist_train, mnist_test = load_augmented_mnist()\n",
    "\n",
    "        # Combine experimental data with augmented MNIST data\n",
    "        combined_dataset = ConcatDataset([MixedDataset(exp_dataset), MixedDataset(mnist_train)])\n",
    "\n",
    "        # Perform K-Fold Cross Validation\n",
    "        fold_results = k_fold_cross_validation(combined_dataset, num_folds=num_folds, num_epochs=num_epochs, patience=patience)\n",
    "        print(f\"Model {i+1} - Average Validation Accuracy across folds: {np.mean(fold_results):.2f}%\")\n",
    "\n",
    "        # Train final model on all data\n",
    "        final_train_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "        final_val_loader = DataLoader(MixedDataset(mnist_test), batch_size=32, shuffle=False)\n",
    "\n",
    "        model = LeNet5_16x16(num_classes=10).to(device)\n",
    "        \n",
    "        # Calculate class weights for the final model\n",
    "        all_labels = []\n",
    "        for dataset in combined_dataset.datasets:\n",
    "            if isinstance(dataset, TensorDataset):\n",
    "                all_labels.extend(dataset.tensors[1].tolist())\n",
    "            else:\n",
    "                all_labels.extend([label for _, label in dataset])\n",
    "        \n",
    "        labels = torch.tensor(all_labels)\n",
    "        class_counts = torch.bincount(labels)\n",
    "        class_weights = 1. / class_counts.float()\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model = train_model(model, final_train_loader, final_val_loader, criterion, optimizer, num_epochs=num_epochs, patience=patience)\n",
    "        \n",
    "        ensemble.append(model)\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f\"lenet5_trained_model_ensemble_{i+1}.pth\")\n",
    "        print(f\"Model {i+1} saved as lenet5_trained_model_ensemble_{i+1}.pth\")\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def ensemble_predict(ensemble, input_tensor):\n",
    "    predictions = []\n",
    "    for model in ensemble:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            predictions.append(torch.softmax(output, dim=1))\n",
    "    \n",
    "    avg_prediction = torch.mean(torch.stack(predictions), dim=0)\n",
    "    return torch.argmax(avg_prediction, dim=1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ensemble = train_ensemble(num_models=25, num_folds=5, num_epochs=50, patience=5)\n",
    "    \n",
    "    # Test the ensemble on experimental data\n",
    "    _, _, exp_test_images, exp_test_labels, _ = load_all_experimental_data('test_digits')\n",
    "    exp_test_dataset = TensorDataset(exp_test_images, exp_test_labels)\n",
    "    exp_test_loader = DataLoader(exp_test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in exp_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        predictions = ensemble_predict(ensemble, images)\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Ensemble accuracy on experimental data: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
