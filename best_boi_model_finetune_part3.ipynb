{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "import zipfile\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from mnist_skeptic_v9 import skeptic_v9\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def base64_to_image(self, base64_string):\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('L')\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        return torch.from_numpy(image_array).unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = self.base64_to_image(item['composite'])\n",
    "        label = torch.tensor(int(item['true_digit']), dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "class SelectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = [item for sublist in data for item in sublist]  # Flatten the list of lists\n",
    "\n",
    "    def base64_to_image(self, base64_string):\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('L')\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        return torch.from_numpy(image_array).unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = self.base64_to_image(item['selected_image'])\n",
    "        label = torch.tensor(int(item['true_digit']), dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "def load_data(test_file_path, train_file_path):\n",
    "    with open(test_file_path, 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    with open(train_file_path, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    return test_data, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model_paths):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = nn.ModuleList([skeptic_v9() for _ in range(len(model_paths))])\n",
    "        for model, path in zip(self.models, model_paths):\n",
    "            model.load_state_dict(torch.load(path))\n",
    "            model.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [model(x) for model in self.models]\n",
    "        return torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "def create_ensemble(model_dir='best_boi_models'):\n",
    "    model_paths = [os.path.join(model_dir, f) for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    return EnsembleModel(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight_8=0.5):\n",
    "        super().__init__()\n",
    "        self.weight_8 = weight_8\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        ce_loss = F.cross_entropy(outputs, targets, reduction='none')\n",
    "        weights = torch.ones_like(targets, dtype=torch.float)\n",
    "        weights[targets != 8] = 1 / (1 - self.weight_8)\n",
    "        weights[targets == 8] = self.weight_8\n",
    "        return (ce_loss * weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, train_loader, val_loader, num_epochs=5, learning_rate=0.0001, weight_8=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = WeightedCrossEntropyLoss(weight_8=weight_8)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        class_correct = [0] * 10\n",
    "        class_total = [0] * 10\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for i in range(10):\n",
    "                class_correct[i] += ((predicted == i) & (labels == i)).sum().item()\n",
    "                class_total[i] += (labels == i).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix({'Loss': running_loss/len(progress_bar), 'Accuracy': f'{accuracy:.2f}%'})\n",
    "        \n",
    "        # Print class-wise accuracies\n",
    "        for i in range(10):\n",
    "            class_acc = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "            print(f'Accuracy of {i}: {class_acc:.2f}%')\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f'Epoch {epoch+1} Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        scheduler.step(val_accuracy)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "    \n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\AppData\\Local\\Temp\\ipykernel_28464\\2670887898.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning on composite images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 6/6 [00:00<00:00,  7.14it/s, Loss=4.96, Accuracy=21.43%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 42.86%\n",
      "Accuracy of 1: 37.14%\n",
      "Accuracy of 2: 14.29%\n",
      "Accuracy of 3: 8.57%\n",
      "Accuracy of 4: 11.43%\n",
      "Accuracy of 5: 28.57%\n",
      "Accuracy of 6: 22.86%\n",
      "Accuracy of 7: 17.14%\n",
      "Accuracy of 8: 31.43%\n",
      "Accuracy of 9: 0.00%\n",
      "Epoch 1 Validation Accuracy: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 6/6 [00:00<00:00, 19.56it/s, Loss=4.87, Accuracy=20.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 31.43%\n",
      "Accuracy of 1: 28.57%\n",
      "Accuracy of 2: 17.14%\n",
      "Accuracy of 3: 11.43%\n",
      "Accuracy of 4: 11.43%\n",
      "Accuracy of 5: 37.14%\n",
      "Accuracy of 6: 20.00%\n",
      "Accuracy of 7: 17.14%\n",
      "Accuracy of 8: 25.71%\n",
      "Accuracy of 9: 0.00%\n",
      "Epoch 2 Validation Accuracy: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 6/6 [00:00<00:00, 20.23it/s, Loss=4.73, Accuracy=21.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 40.00%\n",
      "Accuracy of 1: 37.14%\n",
      "Accuracy of 2: 17.14%\n",
      "Accuracy of 3: 11.43%\n",
      "Accuracy of 4: 8.57%\n",
      "Accuracy of 5: 28.57%\n",
      "Accuracy of 6: 25.71%\n",
      "Accuracy of 7: 20.00%\n",
      "Accuracy of 8: 28.57%\n",
      "Accuracy of 9: 0.00%\n",
      "Epoch 3 Validation Accuracy: 9.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 6/6 [00:00<00:00, 19.10it/s, Loss=4.65, Accuracy=21.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 42.86%\n",
      "Accuracy of 1: 31.43%\n",
      "Accuracy of 2: 14.29%\n",
      "Accuracy of 3: 8.57%\n",
      "Accuracy of 4: 14.29%\n",
      "Accuracy of 5: 37.14%\n",
      "Accuracy of 6: 25.71%\n",
      "Accuracy of 7: 17.14%\n",
      "Accuracy of 8: 25.71%\n",
      "Accuracy of 9: 0.00%\n",
      "Epoch 4 Validation Accuracy: 9.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 6/6 [00:00<00:00, 17.96it/s, Loss=4.58, Accuracy=20.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 37.14%\n",
      "Accuracy of 1: 31.43%\n",
      "Accuracy of 2: 20.00%\n",
      "Accuracy of 3: 11.43%\n",
      "Accuracy of 4: 11.43%\n",
      "Accuracy of 5: 28.57%\n",
      "Accuracy of 6: 25.71%\n",
      "Accuracy of 7: 17.14%\n",
      "Accuracy of 8: 17.14%\n",
      "Accuracy of 9: 0.00%\n",
      "Epoch 5 Validation Accuracy: 11.71%\n",
      "Fine-tuning on selection images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 2051/2051 [01:39<00:00, 20.66it/s, Loss=4.27, Accuracy=10.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 16.88%\n",
      "Accuracy of 1: 14.96%\n",
      "Accuracy of 2: 6.77%\n",
      "Accuracy of 3: 9.85%\n",
      "Accuracy of 4: 24.50%\n",
      "Accuracy of 5: 11.72%\n",
      "Accuracy of 6: 3.98%\n",
      "Accuracy of 7: 10.10%\n",
      "Accuracy of 8: 0.78%\n",
      "Accuracy of 9: 3.44%\n",
      "Epoch 1 Validation Accuracy: 14.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 2051/2051 [01:38<00:00, 20.72it/s, Loss=4.19, Accuracy=10.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 17.21%\n",
      "Accuracy of 1: 19.18%\n",
      "Accuracy of 2: 6.19%\n",
      "Accuracy of 3: 12.15%\n",
      "Accuracy of 4: 17.61%\n",
      "Accuracy of 5: 9.73%\n",
      "Accuracy of 6: 8.00%\n",
      "Accuracy of 7: 11.23%\n",
      "Accuracy of 8: 0.00%\n",
      "Accuracy of 9: 6.18%\n",
      "Epoch 2 Validation Accuracy: 15.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 2051/2051 [01:35<00:00, 21.38it/s, Loss=4.18, Accuracy=11.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 17.98%\n",
      "Accuracy of 1: 22.40%\n",
      "Accuracy of 2: 6.02%\n",
      "Accuracy of 3: 9.68%\n",
      "Accuracy of 4: 18.04%\n",
      "Accuracy of 5: 10.45%\n",
      "Accuracy of 6: 9.74%\n",
      "Accuracy of 7: 10.93%\n",
      "Accuracy of 8: 0.00%\n",
      "Accuracy of 9: 8.19%\n",
      "Epoch 3 Validation Accuracy: 16.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 2051/2051 [01:28<00:00, 23.07it/s, Loss=4.17, Accuracy=12.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 18.58%\n",
      "Accuracy of 1: 25.56%\n",
      "Accuracy of 2: 6.90%\n",
      "Accuracy of 3: 9.14%\n",
      "Accuracy of 4: 18.58%\n",
      "Accuracy of 5: 10.51%\n",
      "Accuracy of 6: 11.73%\n",
      "Accuracy of 7: 10.43%\n",
      "Accuracy of 8: 0.00%\n",
      "Accuracy of 9: 8.69%\n",
      "Epoch 4 Validation Accuracy: 18.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 2051/2051 [01:28<00:00, 23.30it/s, Loss=4.17, Accuracy=12.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0: 18.00%\n",
      "Accuracy of 1: 27.71%\n",
      "Accuracy of 2: 7.83%\n",
      "Accuracy of 3: 7.44%\n",
      "Accuracy of 4: 19.40%\n",
      "Accuracy of 5: 12.14%\n",
      "Accuracy of 6: 13.20%\n",
      "Accuracy of 7: 11.03%\n",
      "Accuracy of 8: 0.00%\n",
      "Accuracy of 9: 7.81%\n",
      "Epoch 5 Validation Accuracy: 18.00%\n",
      "Fine-tuned model saved as 'ensemble_finetuned_megaload.pth'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the pre-trained ensemble model\n",
    "    ensemble_model = create_ensemble()\n",
    "    \n",
    "    # Load data\n",
    "    test_data, train_data = load_data('training_data/test_set/participant_0.json', 'training_data/training_set/participant_0.json')\n",
    "    \n",
    "    # Create datasets\n",
    "    train_composite_dataset = CompositeDataset(test_data)  # Using test_data for composite images\n",
    "    train_selection_dataset = SelectionDataset(train_data)\n",
    "    val_composite_dataset = CompositeDataset(test_data)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_composite_loader = DataLoader(train_composite_dataset, batch_size=64, shuffle=True)\n",
    "    train_selection_loader = DataLoader(train_selection_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_composite_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Fine-tune the model on composite images\n",
    "    print(\"Fine-tuning on composite images...\")\n",
    "    fine_tuned_model = fine_tune_model(ensemble_model, train_composite_loader, val_loader, weight_8=0.5)\n",
    "    \n",
    "    # Further fine-tune on selection images\n",
    "    print(\"Fine-tuning on selection images...\")\n",
    "    final_model = fine_tune_model(fine_tuned_model, train_selection_loader, val_loader, weight_8=0.5)\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    torch.save(final_model.state_dict(), 'ensemble_finetuned_megaload.pth')\n",
    "    print(\"Fine-tuned model saved as 'ensemble_finetuned_megaload.pth'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\AppData\\Local\\Temp\\ipykernel_42016\\2670887898.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning on composite images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sai\\Desktop\\NN_digit_classifier\\Southampton_NN_digit_classifier\\env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|██████████| 28/28 [00:01<00:00, 15.79it/s, Loss=2.59, Accuracy=18.74%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Accuracy: 10.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 28/28 [00:01<00:00, 22.44it/s, Loss=2.41, Accuracy=19.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Accuracy: 19.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 28/28 [00:01<00:00, 21.24it/s, Loss=2.3, Accuracy=19.37%]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Accuracy: 20.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 28/28 [00:01<00:00, 20.53it/s, Loss=2.24, Accuracy=20.86%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation Accuracy: 21.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 28/28 [00:01<00:00, 21.03it/s, Loss=2.19, Accuracy=21.49%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Accuracy: 22.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 28/28 [00:01<00:00, 20.67it/s, Loss=2.15, Accuracy=22.69%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Accuracy: 24.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 28/28 [00:01<00:00, 23.15it/s, Loss=2.11, Accuracy=23.89%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Accuracy: 25.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 28/28 [00:01<00:00, 21.89it/s, Loss=2.09, Accuracy=25.60%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Accuracy: 26.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 28/28 [00:01<00:00, 22.26it/s, Loss=2.05, Accuracy=26.29%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Accuracy: 28.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 28/28 [00:01<00:00, 21.28it/s, Loss=2.02, Accuracy=27.89%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation Accuracy: 29.31%\n",
      "Fine-tuning on selection images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 10254/10254 [07:56<00:00, 21.50it/s, Loss=2.3, Accuracy=11.33%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Accuracy: 21.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 10254/10254 [07:58<00:00, 21.44it/s, Loss=2.29, Accuracy=12.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Accuracy: 34.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 10254/10254 [07:55<00:00, 21.56it/s, Loss=2.28, Accuracy=13.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Accuracy: 45.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 10254/10254 [07:57<00:00, 21.47it/s, Loss=2.27, Accuracy=13.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation Accuracy: 48.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 10254/10254 [08:01<00:00, 21.32it/s, Loss=2.27, Accuracy=14.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Accuracy: 55.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 10254/10254 [07:59<00:00, 21.40it/s, Loss=2.26, Accuracy=14.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Accuracy: 54.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 10254/10254 [08:02<00:00, 21.27it/s, Loss=2.26, Accuracy=14.98%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Accuracy: 54.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 10254/10254 [07:56<00:00, 21.51it/s, Loss=2.25, Accuracy=15.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Accuracy: 52.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 10254/10254 [07:56<00:00, 21.52it/s, Loss=2.25, Accuracy=15.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Accuracy: 50.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10254/10254 [07:55<00:00, 21.57it/s, Loss=2.24, Accuracy=16.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation Accuracy: 49.89%\n",
      "Fine-tuned model saved as 'best_boi_models_finetuned_advanced/ensemble_finetuned_megaload2.pth'\n"
     ]
    }
   ],
   "source": [
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        return F.cross_entropy(outputs, targets, weight=self.class_weights)\n",
    "\n",
    "class CompositeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def base64_to_image(self, base64_string):\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('L')\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        return torch.from_numpy(image_array).unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = self.base64_to_image(item['composite'])\n",
    "        label = torch.tensor(int(item['true_digit']), dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "class SelectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = [item for sublist in data for item in sublist]\n",
    "\n",
    "    def base64_to_image(self, base64_string):\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('L')\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        return torch.from_numpy(image_array).unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = self.base64_to_image(item['selected_image'])\n",
    "        label = torch.tensor(int(item['true_digit']), dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "def load_data(train_folder, test_folder, num_participants=5):\n",
    "    train_data = []\n",
    "    for file in os.listdir(train_folder)[:num_participants]:\n",
    "        with open(os.path.join(train_folder, file), 'r') as f:\n",
    "            train_data.extend(json.load(f))\n",
    "    \n",
    "    test_data = []\n",
    "    for file in os.listdir(test_folder)[:num_participants]:  # Use the same number of participants for test data\n",
    "        with open(os.path.join(test_folder, file), 'r') as f:\n",
    "            test_data.extend(json.load(f))\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def calculate_class_weights(dataset):\n",
    "    class_counts = torch.zeros(10)\n",
    "    for _, label in dataset:\n",
    "        class_counts[label] += 1\n",
    "    class_weights = 1.0 / class_counts\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "    return class_weights\n",
    "\n",
    "def fine_tune_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.0001, class_weights=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = WeightedCrossEntropyLoss(class_weights.to(device) if class_weights is not None else None)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix({'Loss': running_loss/len(progress_bar), 'Accuracy': f'{accuracy:.2f}%'})\n",
    "        \n",
    "        # Validation\n",
    "        val_accuracy = evaluate_model(model, val_loader, device)\n",
    "        print(f'Epoch {epoch+1} Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        scheduler.step(val_accuracy)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "    \n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def main():\n",
    "    # Load the pre-trained ensemble model\n",
    "    ensemble_model = create_ensemble()\n",
    "    \n",
    "    # Load data\n",
    "    train_data, test_data = load_data('training_data/training_set', 'training_data/test_set', num_participants=5)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_composite_dataset = CompositeDataset(test_data)\n",
    "    train_selection_dataset = SelectionDataset(train_data)\n",
    "    val_composite_dataset = CompositeDataset(test_data)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = calculate_class_weights(ConcatDataset([train_composite_dataset, train_selection_dataset]))\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_composite_loader = DataLoader(train_composite_dataset, batch_size=64, shuffle=True)\n",
    "    train_selection_loader = DataLoader(train_selection_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_composite_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Fine-tune the model on composite images\n",
    "    print(\"Fine-tuning on composite images...\")\n",
    "    fine_tuned_model = fine_tune_model(ensemble_model, train_composite_loader, val_loader, class_weights=class_weights)\n",
    "    \n",
    "    # Further fine-tune on selection images\n",
    "    print(\"Fine-tuning on selection images...\")\n",
    "    final_model = fine_tune_model(fine_tuned_model, train_selection_loader, val_loader, class_weights=class_weights)\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    save_model_path = 'best_boi_models_finetuned_advanced/ensemble_finetuned_megaload2.pth'\n",
    "    os.makedirs(os.path.dirname(save_model_path), exist_ok=True)\n",
    "    torch.save(final_model.state_dict(), save_model_path)\n",
    "    print(f\"Fine-tuned model saved as '{save_model_path}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh baby this is going to be interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from mnist_skeptic_v9 import skeptic_v9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\AppData\\Local\\Temp\\ipykernel_42016\\2670887898.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning on composite images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/12: 100%|██████████| 55/55 [00:02<00:00, 20.95it/s, Loss=2.52, Accuracy=18.71%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Accuracy: 19.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/12: 100%|██████████| 55/55 [00:02<00:00, 20.09it/s, Loss=2.3, Accuracy=19.94%]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Accuracy: 21.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/12: 100%|██████████| 55/55 [00:02<00:00, 20.18it/s, Loss=2.19, Accuracy=21.71%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Accuracy: 23.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/12: 100%|██████████| 55/55 [00:02<00:00, 20.93it/s, Loss=2.13, Accuracy=23.03%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation Accuracy: 24.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/12: 100%|██████████| 55/55 [00:02<00:00, 21.13it/s, Loss=2.08, Accuracy=24.86%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Accuracy: 26.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/12: 100%|██████████| 55/55 [00:02<00:00, 20.19it/s, Loss=2.05, Accuracy=26.26%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Accuracy: 27.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/12: 100%|██████████| 55/55 [00:02<00:00, 21.44it/s, Loss=2.01, Accuracy=27.66%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Accuracy: 29.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/12: 100%|██████████| 55/55 [00:02<00:00, 20.78it/s, Loss=1.99, Accuracy=29.17%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Accuracy: 29.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/12: 100%|██████████| 55/55 [00:02<00:00, 21.29it/s, Loss=1.97, Accuracy=29.89%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Accuracy: 30.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/12: 100%|██████████| 55/55 [00:02<00:00, 19.68it/s, Loss=1.96, Accuracy=31.11%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation Accuracy: 31.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/12: 100%|██████████| 55/55 [00:02<00:00, 21.09it/s, Loss=1.95, Accuracy=30.51%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation Accuracy: 30.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/12: 100%|██████████| 55/55 [00:02<00:00, 21.68it/s, Loss=1.95, Accuracy=30.63%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation Accuracy: 30.97%\n",
      "Fine-tuning on selection images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/12: 100%|██████████| 20508/20508 [16:37<00:00, 20.56it/s, Loss=2.29, Accuracy=12.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Accuracy: 40.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/12: 100%|██████████| 20508/20508 [16:37<00:00, 20.56it/s, Loss=2.28, Accuracy=13.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Accuracy: 42.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/12: 100%|██████████| 20508/20508 [16:33<00:00, 20.64it/s, Loss=2.27, Accuracy=13.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Accuracy: 50.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/12: 100%|██████████| 20508/20508 [16:34<00:00, 20.61it/s, Loss=2.27, Accuracy=14.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation Accuracy: 54.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/12: 100%|██████████| 20508/20508 [16:37<00:00, 20.57it/s, Loss=2.27, Accuracy=14.21%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Accuracy: 54.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/12: 100%|██████████| 20508/20508 [16:36<00:00, 20.58it/s, Loss=2.27, Accuracy=14.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Accuracy: 55.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/12: 100%|██████████| 20508/20508 [16:38<00:00, 20.54it/s, Loss=2.26, Accuracy=14.53%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Accuracy: 55.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/12: 100%|██████████| 20508/20508 [16:37<00:00, 20.57it/s, Loss=2.26, Accuracy=14.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Accuracy: 57.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/12: 100%|██████████| 20508/20508 [16:33<00:00, 20.65it/s, Loss=2.26, Accuracy=14.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Accuracy: 58.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/12: 100%|██████████| 20508/20508 [16:36<00:00, 20.59it/s, Loss=2.26, Accuracy=14.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation Accuracy: 58.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/12: 100%|██████████| 20508/20508 [16:35<00:00, 20.60it/s, Loss=2.26, Accuracy=15.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation Accuracy: 57.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/12: 100%|██████████| 20508/20508 [16:35<00:00, 20.59it/s, Loss=2.26, Accuracy=15.08%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation Accuracy: 57.80%\n",
      "Fine-tuned model saved as 'best_boi_models_finetuned_advanced/ensemble_finetuned_megaload3.pth'\n"
     ]
    }
   ],
   "source": [
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        return F.cross_entropy(outputs, targets, weight=self.class_weights)\n",
    "\n",
    "class CompositeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def base64_to_image(self, base64_string):\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('L')\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        return torch.from_numpy(image_array).unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = self.base64_to_image(item['composite'])\n",
    "        label = torch.tensor(int(item['true_digit']), dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "class SelectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = [item for sublist in data for item in sublist]\n",
    "\n",
    "    def base64_to_image(self, base64_string):\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('L')\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        return torch.from_numpy(image_array).unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = self.base64_to_image(item['selected_image'])\n",
    "        label = torch.tensor(int(item['true_digit']), dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "def load_data(train_folder, test_folder, num_participants=10):\n",
    "    train_data = []\n",
    "    for file in os.listdir(train_folder)[:num_participants]:\n",
    "        with open(os.path.join(train_folder, file), 'r') as f:\n",
    "            train_data.extend(json.load(f))\n",
    "    \n",
    "    test_data = []\n",
    "    for file in os.listdir(test_folder)[:num_participants]:\n",
    "        with open(os.path.join(test_folder, file), 'r') as f:\n",
    "            test_data.extend(json.load(f))\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def fine_tune_model(model, train_loader, val_loader, num_epochs=12, learning_rate=0.0001, class_weights=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = WeightedCrossEntropyLoss(class_weights.to(device) if class_weights is not None else None)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_model_state = None\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix({'Loss': running_loss/len(progress_bar), 'Accuracy': f'{accuracy:.2f}%'})\n",
    "        \n",
    "        # Validation\n",
    "        val_accuracy = evaluate_model(model, val_loader, device)\n",
    "        print(f'Epoch {epoch+1} Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"Early stopping triggered. No improvement for {patience} epochs.\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Load the pre-trained ensemble model\n",
    "    ensemble_model = create_ensemble()\n",
    "    \n",
    "    # Load data\n",
    "    train_data, test_data = load_data('training_data/training_set', 'training_data/test_set', num_participants=10)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_composite_dataset = CompositeDataset(test_data)\n",
    "    train_selection_dataset = SelectionDataset(train_data)\n",
    "    val_composite_dataset = CompositeDataset(test_data)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = calculate_class_weights(ConcatDataset([train_composite_dataset, train_selection_dataset]))\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_composite_loader = DataLoader(train_composite_dataset, batch_size=64, shuffle=True)\n",
    "    train_selection_loader = DataLoader(train_selection_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_composite_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Fine-tune the model on composite images\n",
    "    print(\"Fine-tuning on composite images...\")\n",
    "    fine_tuned_model = fine_tune_model(ensemble_model, train_composite_loader, val_loader, class_weights=class_weights)\n",
    "    \n",
    "    # Further fine-tune on selection images\n",
    "    print(\"Fine-tuning on selection images...\")\n",
    "    final_model = fine_tune_model(fine_tuned_model, train_selection_loader, val_loader, class_weights=class_weights)\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    save_model_path = 'best_boi_models_finetuned_advanced/ensemble_finetuned_megaload3.pth'\n",
    "    os.makedirs(os.path.dirname(save_model_path), exist_ok=True)\n",
    "    torch.save(final_model.state_dict(), save_model_path)\n",
    "    print(f\"Fine-tuned model saved as '{save_model_path}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
