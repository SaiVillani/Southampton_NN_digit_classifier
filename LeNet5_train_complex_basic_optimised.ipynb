{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, ConcatDataset\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import os\n",
    "import zipfile\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import time\n",
    "import subprocess\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental data\n",
    "def load_all_experimental_data(test_digits_folder):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    participant_data = {}\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((16, 16)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    for filename in os.listdir(test_digits_folder):\n",
    "        if filename.endswith('.zip') and filename.startswith('experiment_results_participant'):\n",
    "            participant_number = int(filename.split('participant')[1].split('.')[0])\n",
    "            zip_filepath = os.path.join(test_digits_folder, filename)\n",
    "\n",
    "            participant_train_images = []\n",
    "            participant_train_labels = []\n",
    "            participant_test_images = []\n",
    "            participant_test_labels = []\n",
    "\n",
    "            with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "                for img_filename in zip_ref.namelist():\n",
    "                    if img_filename.endswith('.png'):\n",
    "                        with zip_ref.open(img_filename) as file:\n",
    "                            img = Image.open(file).convert('L')\n",
    "                            img_tensor = transform(img)\n",
    "                            \n",
    "                            digit = int(img_filename.split('_')[0])\n",
    "                            \n",
    "                            if 'composite' in img_filename:\n",
    "                                test_images.append(img_tensor)\n",
    "                                test_labels.append(digit)\n",
    "                                participant_test_images.append(img_tensor)\n",
    "                                participant_test_labels.append(digit)\n",
    "                            else:\n",
    "                                train_images.append(img_tensor)\n",
    "                                train_labels.append(digit)\n",
    "                                participant_train_images.append(img_tensor)\n",
    "                                participant_train_labels.append(digit)\n",
    "\n",
    "            participant_data[participant_number] = {\n",
    "                'train': (torch.stack(participant_train_images), torch.tensor(participant_train_labels)),\n",
    "                'test': (torch.stack(participant_test_images), torch.tensor(participant_test_labels))\n",
    "            }\n",
    "\n",
    "    return (torch.stack(train_images), torch.tensor(train_labels), \n",
    "            torch.stack(test_images), torch.tensor(test_labels),\n",
    "            participant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(self.dataset, TensorDataset):\n",
    "            x, y = self.dataset[index]\n",
    "        else:\n",
    "            x, y = self.dataset[index]\n",
    "        \n",
    "        # Ensure x is a tensor\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x)\n",
    "        \n",
    "        # Ensure y is a tensor\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.tensor(y)\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class LeNet5_16x16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5_16x16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device):\n",
    "    model = model.to(device)\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}')\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                outputs_val = model(val_images)\n",
    "                _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (predicted_val == val_labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "def k_fold_cross_validation(dataset, num_folds=5, num_epochs=50, patience=5):\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(range(len(dataset)))):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_index)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_index)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = LeNet5_16x16(num_classes=10).to(device)\n",
    "        \n",
    "        # Calculate class weights for weighted cross-entropy\n",
    "        labels = torch.tensor([dataset[i][1] for i in train_index])\n",
    "        class_counts = torch.bincount(labels)\n",
    "        class_weights = 1. / class_counts.float()\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                outputs_val = model(val_images)\n",
    "                _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (predicted_val == val_labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        fold_results.append(val_accuracy)\n",
    "        print(f'Fold {fold + 1} Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional data augmentation techniques\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "def load_augmented_mnist():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((16, 16)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "            AddGaussianNoise(0., 0.05),\n",
    "        ], p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n",
    "        ], p=0.3),\n",
    "    ])\n",
    "    \n",
    "    invert_transform = transforms.Compose([\n",
    "        transform,\n",
    "        transforms.Lambda(lambda x: 1 - x),\n",
    "    ])\n",
    "    \n",
    "    mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    inverted_mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=invert_transform)\n",
    "    inverted_mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=invert_transform)\n",
    "    \n",
    "    combined_train = ConcatDataset([mnist_train, inverted_mnist_train])\n",
    "    combined_test = ConcatDataset([mnist_test, inverted_mnist_test])\n",
    "    \n",
    "    return combined_train, combined_test\n",
    "\n",
    "def ensemble_predict(ensemble, input_tensor):\n",
    "    predictions = []\n",
    "    for model in ensemble:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            predictions.append(torch.softmax(output, dim=1))\n",
    "    \n",
    "    avg_prediction = torch.mean(torch.stack(predictions), dim=0)\n",
    "    return torch.argmax(avg_prediction, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(num_models=25, num_folds=5, num_epochs=50, patience=5, target_time=14*3600):\n",
    "    ensemble = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        print(f\"Training model {i+1}/{num_models}\")\n",
    "        \n",
    "        # Load and prepare data\n",
    "        exp_train_images, exp_train_labels, exp_test_images, exp_test_labels, participant_data = load_all_experimental_data('test_digits')\n",
    "        exp_dataset = TensorDataset(exp_train_images, exp_train_labels)\n",
    "        mnist_train, mnist_test = load_augmented_mnist()\n",
    "        combined_dataset = ConcatDataset([MixedDataset(exp_dataset), MixedDataset(mnist_train)])\n",
    "\n",
    "        # Perform K-Fold Cross Validation\n",
    "        kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "        fold_results = []\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(range(len(combined_dataset)))):\n",
    "            print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "            train_subset = torch.utils.data.Subset(combined_dataset, train_index)\n",
    "            val_subset = torch.utils.data.Subset(combined_dataset, val_index)\n",
    "\n",
    "            train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "            val_loader = DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "            model = LeNet5_16x16(num_classes=10).to(device)\n",
    "            \n",
    "            # Calculate class weights for weighted cross-entropy\n",
    "            labels = torch.tensor([combined_dataset[i][1] for i in train_index])\n",
    "            class_counts = torch.bincount(labels)\n",
    "            class_weights = 1. / class_counts.float()\n",
    "            class_weights = class_weights / class_weights.sum()\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "            model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device)\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            model.eval()\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_labels in val_loader:\n",
    "                    val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                    outputs_val = model(val_images)\n",
    "                    _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "                    total_val += val_labels.size(0)\n",
    "                    correct_val += (predicted_val == val_labels).sum().item()\n",
    "            \n",
    "            val_accuracy = 100 * correct_val / total_val\n",
    "            fold_results.append(val_accuracy)\n",
    "            print(f'Fold {fold + 1} Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        print(f\"Model {i+1} - Average Validation Accuracy across folds: {np.mean(fold_results):.2f}%\")\n",
    "\n",
    "        # Train final model on all data\n",
    "        final_train_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        final_val_loader = DataLoader(MixedDataset(mnist_test), batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        model = LeNet5_16x16(num_classes=10).to(device)\n",
    "        \n",
    "        # Calculate class weights for the final model\n",
    "        all_labels = []\n",
    "        for dataset in combined_dataset.datasets:\n",
    "            if isinstance(dataset, TensorDataset):\n",
    "                all_labels.extend(dataset.tensors[1].tolist())\n",
    "            else:\n",
    "                all_labels.extend([label for _, label in dataset])\n",
    "        \n",
    "        labels = torch.tensor(all_labels)\n",
    "        class_counts = torch.bincount(labels)\n",
    "        class_weights = 1. / class_counts.float()\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model = train_model(model, final_train_loader, final_val_loader, criterion, optimizer, num_epochs=num_epochs, patience=patience, device=device)\n",
    "        \n",
    "        ensemble.append(model)\n",
    "        \n",
    "        # Save the model\n",
    "        os.makedirs('lenet5_ensemble', exist_ok=True)\n",
    "        torch.save(model.state_dict(), f\"lenet5_ensemble/lenet5_trained_model_ensemble_{i+1}.pth\")\n",
    "        print(f\"Model {i+1} saved as lenet5_ensemble/lenet5_trained_model_ensemble_{i+1}.pth\")\n",
    "\n",
    "        # Check if we're close to the target time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= target_time:\n",
    "            print(f\"Target time reached. Stopping after training {i+1} models.\")\n",
    "            break\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training model 1/25\n",
      "Fold 1/5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'load_augmented_mnist.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Set the number of CPU threads for PyTorch\u001b[39;00m\n\u001b[0;32m     15\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_num_threads(\u001b[38;5;241m8\u001b[39m)  \u001b[38;5;66;03m# Adjust this based on your CPU\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Test the ensemble on experimental data\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _, _, exp_test_images, exp_test_labels, _ \u001b[38;5;241m=\u001b[39m load_all_experimental_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_digits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 37\u001b[0m, in \u001b[0;36mtrain_ensemble\u001b[1;34m(num_models, num_folds, num_epochs, patience, target_time)\u001b[0m\n\u001b[0;32m     33\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39mclass_weights\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     35\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[12], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     36\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     39\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     40\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Sai\\Desktop\\NN_digit_classifier\\Southampton_NN_digit_classifier\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sai\\Desktop\\NN_digit_classifier\\Southampton_NN_digit_classifier\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sai\\Desktop\\NN_digit_classifier\\Southampton_NN_digit_classifier\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'load_augmented_mnist.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "def commit_and_push_changes():\n",
    "    try:\n",
    "        subprocess.run(['git', 'add', '.'], check=True)\n",
    "        subprocess.run(['git', 'commit', '-m', 'Auto commit after training ensemble models'], check=True)\n",
    "        subprocess.run(['git', 'push', 'origin_NN', 'main'], check=True)\n",
    "        print('All changes committed and pushed successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Set the number of CPU threads for PyTorch\n",
    "    torch.set_num_threads(8)  # Adjust this based on your CPU\n",
    "\n",
    "    ensemble = train_ensemble(num_models=25, num_folds=5, num_epochs=50, patience=5, target_time=14*3600)\n",
    "    \n",
    "    # Test the ensemble on experimental data\n",
    "    _, _, exp_test_images, exp_test_labels, _ = load_all_experimental_data('test_digits')\n",
    "    exp_test_dataset = TensorDataset(exp_test_images, exp_test_labels)\n",
    "    exp_test_loader = DataLoader(exp_test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in exp_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        predictions = ensemble_predict(ensemble, images)\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Ensemble accuracy on experimental data: {accuracy:.2f}%\")\n",
    "\n",
    "    # Commit and push changes\n",
    "    commit_and_push_changes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
