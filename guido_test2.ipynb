{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "class LeNet5_16x16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5_16x16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "def load_ensemble(num_models=25):\n",
    "    ensemble = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        model = LeNet5_16x16(num_classes=10).to(device)\n",
    "        model.load_state_dict(torch.load(f\"lenet5_trained_model_ensemble_{i+1}.pth\", map_location=device))\n",
    "        model.eval()\n",
    "        ensemble.append(model)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def load_and_visualize_csv(file_path):\n",
    "    filename = os.path.basename(file_path)\n",
    "    subject, digit, run = filename.split('_')[1], filename.split('_')[3], filename.split('_')[5].split('.')[0]\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        csv_data = f.read().strip().split('\\n')\n",
    "    \n",
    "    image_data = np.array([list(map(float, row.split(','))) for row in csv_data])\n",
    "    return image_data, int(digit)\n",
    "\n",
    "def preprocess_image(image_data):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    image = Image.fromarray((image_data * 255).astype(np.uint8), mode='L')\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "def ensemble_predict_and_visualize(ensemble, image_tensor):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    predictions = []\n",
    "    for model in ensemble:\n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "            pred = torch.argmax(output, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    prediction_counts = [predictions.count(i) for i in range(10)]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(10), prediction_counts)\n",
    "    plt.title(\"Ensemble Predictions\")\n",
    "    plt.xlabel(\"Digit\")\n",
    "    plt.ylabel(\"Number of Models\")\n",
    "    plt.xticks(range(10))\n",
    "    \n",
    "    for i, count in enumerate(prediction_counts):\n",
    "        plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    avg_prediction = sum(predictions) / len(predictions)\n",
    "    sorted_indices = sorted(range(10), key=lambda i: prediction_counts[i], reverse=True)\n",
    "    top_3_peaks = sorted_indices[:3]\n",
    "    \n",
    "    print(f\"Average prediction: {avg_prediction:.2f}\")\n",
    "    print(f\"Top 3 peaks: {top_3_peaks}\")\n",
    "    \n",
    "    return predictions, avg_prediction, top_3_peaks\n",
    "\n",
    "def evaluate_ensemble(csv_folder, ensemble):\n",
    "    results = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    top_1_correct = 0\n",
    "    top_3_correct = 0\n",
    "\n",
    "    for file in os.listdir(csv_folder):\n",
    "        if file.endswith('.txt'):\n",
    "            total += 1\n",
    "            file_path = os.path.join(csv_folder, file)\n",
    "            image_data, true_label = load_and_visualize_csv(file_path)\n",
    "            image_tensor = preprocess_image(image_data)\n",
    "\n",
    "            predictions, avg_prediction, top_3_peaks = ensemble_predict_and_visualize(ensemble, image_tensor)\n",
    "            \n",
    "            predicted = max(set(predictions), key=predictions.count)\n",
    "            confidence_scores = [predictions.count(i) / len(predictions) for i in range(10)]\n",
    "            true_label_confidence = confidence_scores[true_label]\n",
    "            predicted_confidence = confidence_scores[predicted]\n",
    "            \n",
    "            sorted_scores = sorted(enumerate(confidence_scores), key=lambda x: x[1], reverse=True)\n",
    "            true_label_rank = [i for i, (label, _) in enumerate(sorted_scores) if label == true_label][0] + 1\n",
    "            predicted_rank = [i for i, (label, _) in enumerate(sorted_scores) if label == predicted][0] + 1\n",
    "            distance = abs(true_label_rank - predicted_rank)\n",
    "\n",
    "            if predicted == true_label:\n",
    "                correct += 1\n",
    "            if true_label_rank == 1:\n",
    "                top_1_correct += 1\n",
    "            if true_label_rank <= 3:\n",
    "                top_3_correct += 1\n",
    "\n",
    "            results.append({\n",
    "                'True Label': true_label,\n",
    "                'Predicted Label': predicted,\n",
    "                'Predicted Confidence': f\"{predicted_confidence:.4f}\",\n",
    "                'True Label Confidence': f\"{true_label_confidence:.4f}\",\n",
    "                'True Label Rank': true_label_rank,\n",
    "                'Distance': distance\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    accuracy = (correct / total) * 100\n",
    "    top_1_accuracy = (top_1_correct / total) * 100\n",
    "    top_3_accuracy = (top_3_correct / total) * 100\n",
    "\n",
    "    return results_df, accuracy, top_1_accuracy, top_3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ensemble = load_ensemble(num_models=25)\n",
    "    csv_folder = 'CSV_Images'  # Adjust this to your CSV images folder path\n",
    "    \n",
    "    evaluation_results, accuracy, top_1_accuracy, top_3_accuracy = evaluate_ensemble(csv_folder, ensemble)\n",
    "    \n",
    "    print(tabulate(evaluation_results.head(10), headers='keys', tablefmt='pretty', showindex=False))\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Top-1 Accuracy (true label is model's top prediction): {top_1_accuracy:.2f}%\")\n",
    "    print(f\"Top-3 Accuracy (true label is within model's top 3 predictions): {top_3_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
